#!/usr/bin/env python

import sys
import os
import logging
import subprocess
import json
import time
import pipes
import click
import jmespath

from fnmatch import fnmatch
from threading import Thread
from tabulate import tabulate

class Cache(object):
    def __init__(self, path, seconds, retriever, *retriever_args):
        self.path = path
        self.seconds = seconds
        self.retriever = retriever
        self.retriever_args = retriever_args
        self._obj = None
        self._expiry = None

    def obj(self):
        self._consider_update()
        return self._obj

    def _consider_update(self):
        if self._is_stale():
            self._update()
        elif not self._obj:
            with open(self.path) as f:
                self._obj = json.load(f)

    def _is_stale(self):
        if not self._expiry:
            if not os.path.exists(self.path):
                return True
            self._set_expiry()
        return self._expiry < time.time()

    def _update(self):
        self._obj = self.retriever(*self.retriever_args)
        with open(self.path, 'wb') as f:
            json.dump(self._obj, f)
        self._set_expiry()

    def _set_expiry(self):
        self._expiry = os.path.getmtime(self.path) + self.seconds

class BackgroundPopen(subprocess.Popen):
    @staticmethod
    def prefix_handler(prefix, io):
        return lambda line: io.write(prefix + line)

    @staticmethod
    def _proxy_lines(pipe, handler):
        with pipe:
            for line in pipe:
                handler(line)

    def __init__(self, out_handler, err_handler, *args, **kwargs):
        kwargs['stdout'] = subprocess.PIPE
        kwargs['stderr'] = subprocess.PIPE
        super(self.__class__, self).__init__(*args, **kwargs)
        Thread(target=self._proxy_lines, args=[self.stdout, out_handler]).start()
        Thread(target=self._proxy_lines, args=[self.stderr, err_handler]).start()

class KubeCtl(object):
    def __init__(self):
        self._kubectl = subprocess.check_output('which kubectl', shell=True).strip()
        self._processes = []
        self._threads = []
        self.final_rc = 0

    @property
    def context(self):
        return subprocess.check_output(self._commandline('config', 'current-context')).strip()

    def call(self, cmd, *args):
        cl = self._commandline(cmd, *args)
        return self._check(cl, subprocess.call(cl))

    def call_json(self, cmd, *args):
        cl = self._commandline(cmd, '--output=json', *args)
        return json.loads(subprocess.check_output(cl))

    def call_async(self, cmd, *args):
        cl = self._commandline(cmd, *args)
        self._processes.append((cl, subprocess.Popen(cl)))
        return 0

    def call_prefix(self, cmd, prefix, *args):
        out_handler = BackgroundPopen.prefix_handler(prefix, sys.stdout)
        err_handler = BackgroundPopen.prefix_handler('[ERR] ' + prefix, sys.stderr)
        cl = self._commandline(cmd, *args)
        self._processes.append((cl, BackgroundPopen(out_handler, err_handler, cl)))
        return 0

    def wait(self):
        procs = self._processes
        self._process = []
        for cl, proc in procs:
            self._check(cl, proc.wait())
        return self.final_rc

    def _commandline(self, command, *args):
        commandline = (self._kubectl, command) + args
        _logger.debug(' '.join(commandline))
        return commandline

    def _check(self, cl, rc):
        if rc != 0:
            self._final_rc = rc
            _logger.warn('%s => exit status: %d' % (' '.join(cl), rc))
        return rc

######################################################################

ANY_NAMESPACE = '*'
ALL_PODS = '*'
ALL_CONTAINERS = '*'

COLUMN_MAP = {
    'name': 'metadata.name',
    'namespace': 'metadata.namespace',
    'node': 'spec.nodeName',
    'node-ip': 'status.hostIP',
    'status': 'status.phase',
    'containers': 'status.containerStatuses[*].name',
}

BN = os.path.basename(__file__)
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s #%(process)d] %(levelname)-8s %(name)-12s %(message)s',
    datefmt='%Y-%m-%dT%H:%M:%S%z'
)
_logger = logging.getLogger(BN)

# TODO: consider ability to use --context w/o needing to switch
#       (be best if this can be saved in a configstruct!)

# TODO: consider if this would be more useful to always require matcher arguments for namespace,
# pod, container? like `kubey collab-production collab *`? and make them implicitly wrapped in
# '*FOO*' unless a wildcard is provided? i.e. assume "contains" logic

@click.group(context_settings=dict(help_option_names=['-h', '--help']))
@click.option('-n', '--namespace', default=ANY_NAMESPACE, show_default=True,
              help='reduce selection within a namespace')
@click.option('--cache-seconds', default=300, show_default=True,
              help='change number of seconds to keep pod info cached')
@click.option('-l', '--log-level', default='info',
              type=click.Choice(['debug', 'info', 'warning', 'error', 'critical']),
              help='set logging level')
@click.pass_context
def cli(ctx, namespace, cache_seconds, log_level):
    _logger.level = getattr(logging, log_level.upper())
    kubectl = KubeCtl()
    pods_cache_fn = os.path.join(os.path.expanduser('~'), '.%s_%s_pods' % (BN, kubectl.context))
    pods_cache = Cache(pods_cache_fn, cache_seconds,
                       kubectl.call_json, 'get', 'pods', '--all-namespaces')
    # TODO: support glob matching?
    if namespace == ANY_NAMESPACE:
        query = 'items[*]'
    else:
        query = 'items[?metadata.namespace==\'%s\']' % (namespace)
    ctx.obj = {
        'kubectl': kubectl,
        'pods_cache': pods_cache,
        'query': query,
    }

@cli.command()
@click.option('-c', '--columns', default=','.join(COLUMN_MAP.keys()), show_default=True,
              help='specify specific columns to show')
@click.pass_obj
def list(obj, columns):
    '''List available pods and containers for current context.'''

    columns = [c.strip() for c in columns.split(',')]
    print tabulate(each_pod(obj, columns), headers=columns)

@cli.command(context_settings=dict(ignore_unknown_options=True))
@click.option('-n', '--name', default=ALL_PODS, show_default=True,
              help='name of pod (supports wildcard "glob" matching)')
@click.option('-c', '--container', default=ALL_CONTAINERS, show_default=True,
              help='name of container (supports wildcard "glob" matching)')
@click.option('-s', '--shell', default='/bin/sh', show_default=True,
              help='alternate shell used for remote execution')
@click.option('-i', '--interactive', is_flag=True,
              help='require interactive session '
                   '(works with REPLs like shells or other command instances needing input)')
@click.option('-a', '--async', is_flag=True,
              help='run commands asynchronously (incompatible with "interactive")')
@click.option('-p', '--prefix', is_flag=True,
              help='add a prefix to all output indicating the pod and container names '
                   '(incompatible with "interactive")')
@click.argument('command')
@click.argument('arguments', nargs=-1, type=click.UNPROCESSED)
@click.pass_obj
def each(obj, name, container, shell, interactive, async, prefix, command, arguments):
    '''Execute a command remotely for each pod matched.'''

    kubectl = obj['kubectl']
    kexec_args = ['exec']
    if prefix:
        kexec = kubectl.call_prefix
        if interactive:
            click.get_current_context().fail('Interactive and prefix do not operate together')
    elif async:
        kexec = kubectl.call_async
        if interactive:
            click.get_current_context().fail('Interactive and async do not operate together')
    else:
        kexec = kubectl.call
        if interactive:
            kexec_args += ['-ti']

    remote_args = ['exec', command] + [pipes.quote(a) for a in arguments]
    remote_cmd = [shell, '-c', ' '.join(remote_args)]

    for (nm, namespace, con) in each_match(obj, name, container):
        args = kexec_args
        if prefix: args.append('[%s:%s] ' % (nm, con))
        args += ['-n', namespace, '-c', con, nm, '--'] + remote_cmd
        kexec(*args)

    if async:
        kubectl.wait()

    if kubectl.final_rc != 0:
        click.get_current_context().exit(kubectl.final_rc)

@cli.command()
@click.option('-n', '--name', default=ALL_PODS, show_default=True,
              help='name of pod (supports wildcard "glob" matching)')
@click.option('-c', '--container', default=ALL_CONTAINERS, show_default=True,
              help='name of container (supports wildcard "glob" matching)')
@click.option('-f', '--follow', is_flag=True,
              help='stream new logs until interrupted')
@click.argument('number', default=click.get_terminal_size()[1])
@click.pass_obj
def tail(obj, name, container, follow, number):
    '''Show recent logs from containers for each pod matched.'''

    kubectl = obj['kubectl']
    log_args = ['--tail', str(number)]
    if follow:
        log_args.append('-f')

    for (nm, namespace, con) in each_match(obj, name, container):
        prefix = '[%s:%s] ' % (nm, con)
        args = ['-n', namespace, '-c', con] + log_args + [nm]
        kubectl.call_prefix('logs', prefix, *args)

    kubectl.wait()
    if kubectl.final_rc != 0:
        click.get_current_context().exit(kubectl.final_rc)

def each_match(obj, name, container):
    for (nm, namespace, containers) in each_pod(obj, ['name', 'namespace', 'containers']):
        if not fnmatch(nm, name):
            continue
        for con in containers:
            if not fnmatch(con, container):
                continue
            yield(nm, namespace, con)

def each_pod(obj, columns):
    query = obj['query'] + '.[' + ','.join([COLUMN_MAP[c] for c in columns]) + ']'
    pods = obj['pods_cache'].obj()
    for pod in jmespath.search(query, pods):
        yield pod

@cli.command(context_settings=dict(ignore_unknown_options=True))
@click.argument('command')
@click.argument('arguments', nargs=-1, type=click.UNPROCESSED)
@click.pass_obj
def call(obj, command, arguments):
    '''Generic proxy for any other kubectl request'''
    kubectl = obj['kubectl']
    items = kubectl.call_json(command, *arguments)['items']
    print tabulate(items, headers='keys')

if __name__ == '__main__':
    cli()
