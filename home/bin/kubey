#!/usr/bin/env python

import sys
import os
import logging
import re
import subprocess
import json
import time
import pipes
import click
import jmespath

from configstruct import OpenStruct
from fnmatch import fnmatch
from threading import Thread
from tabulate import tabulate

class Cache(object):
    def __init__(self, path, seconds, retriever, *retriever_args):
        self.path = path
        self.seconds = seconds
        self.retriever = retriever
        self.retriever_args = retriever_args
        self._obj = None
        self._expiry = None

    def obj(self):
        self._consider_update()
        return self._obj

    def _consider_update(self):
        if self._is_stale():
            self._update()
        elif not self._obj:
            with open(self.path) as f:
                self._obj = json.load(f)

    def _is_stale(self):
        if not self._expiry:
            if not os.path.exists(self.path):
                return True
            self._set_expiry()
        return self._expiry < time.time()

    def _update(self):
        self._obj = self.retriever(*self.retriever_args)
        with open(self.path, 'wb') as f:
            json.dump(self._obj, f)
        self._set_expiry()

    def _set_expiry(self):
        self._expiry = os.path.getmtime(self.path) + self.seconds

class BackgroundPopen(subprocess.Popen):
    @staticmethod
    def prefix_handler(prefix, io):
        return lambda line: io.write(prefix + line)

    @staticmethod
    def _proxy_lines(pipe, handler):
        with pipe:
            for line in pipe:
                handler(line)

    def __init__(self, out_handler, err_handler, *args, **kwargs):
        kwargs['stdout'] = subprocess.PIPE
        kwargs['stderr'] = subprocess.PIPE
        super(self.__class__, self).__init__(*args, **kwargs)
        Thread(target=self._proxy_lines, args=[self.stdout, out_handler]).start()
        Thread(target=self._proxy_lines, args=[self.stderr, err_handler]).start()

class KubeCtl(object):
    def __init__(self):
        self._kubectl = subprocess.check_output('which kubectl', shell=True).strip()
        self._processes = []
        self._threads = []
        self.final_rc = 0

    @property
    def context(self):
        return subprocess.check_output(self._commandline('config', 'current-context')).strip()

    def call(self, cmd, *args):
        cl = self._commandline(cmd, *args)
        return self._check(cl, subprocess.call(cl))

    def call_json(self, cmd, *args):
        cl = self._commandline(cmd, '--output=json', *args)
        return json.loads(subprocess.check_output(cl))

    def call_async(self, cmd, *args):
        cl = self._commandline(cmd, *args)
        self._processes.append((cl, subprocess.Popen(cl)))
        return 0

    def call_prefix(self, cmd, prefix, *args):
        out_handler = BackgroundPopen.prefix_handler(prefix, sys.stdout)
        err_handler = BackgroundPopen.prefix_handler('[ERR] ' + prefix, sys.stderr)
        cl = self._commandline(cmd, *args)
        self._processes.append((cl, BackgroundPopen(out_handler, err_handler, cl)))
        return 0

    def wait(self):
        procs = self._processes
        self._process = []
        for cl, proc in procs:
            self._check(cl, proc.wait())
        return self.final_rc

    def _commandline(self, command, *args):
        commandline = (self._kubectl, command) + args
        _logger.debug(' '.join(commandline))
        return commandline

    def _check(self, cl, rc):
        if rc != 0:
            self._final_rc = rc
            _logger.warn('%s => exit status: %d' % (' '.join(cl), rc))
        return rc

######################################################################

ANY_NAMESPACE = '*'
ALL_PODS = '*'
ALL_CONTAINERS = '*'

COLUMN_MAP = {
    'name': 'metadata.name',
    'namespace': 'metadata.namespace',
    'node': 'spec.nodeName',
    'node-ip': 'status.hostIP',
    'status': 'status.phase',
    'containers': 'status.containerStatuses[*].name',
}

BN = os.path.basename(__file__)
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s #%(process)d] %(levelname)-8s %(name)-12s %(message)s',
    datefmt='%Y-%m-%dT%H:%M:%S%z'
)
_logger = logging.getLogger(BN)

# TODO: consider ability to use --context w/o needing to switch
#       (be best if this can be saved in a configstruct!)

@click.group(context_settings=dict(help_option_names=['-h', '--help']))
@click.option('--cache-seconds', default=300, show_default=True,
              help='change number of seconds to keep pod info cached')
@click.option('-l', '--log-level', default='info',
              type=click.Choice(['debug', 'info', 'warning', 'error', 'critical']),
              help='set logging level')
@click.argument('namespace')
@click.argument('pod')
@click.argument('container')
@click.pass_context
def cli(ctx, cache_seconds, log_level, namespace, pod, container):
    _logger.level = getattr(logging, log_level.upper())
    kubectl = KubeCtl()
    pods_cache_fn = os.path.join(os.path.expanduser('~'), '.%s_%s_pods' % (BN, kubectl.context))
    pods_cache = Cache(pods_cache_fn, cache_seconds,
                       kubectl.call_json, 'get', 'pods', '--all-namespaces')
    # TODO: support glob matching?
    if namespace == ANY_NAMESPACE:
        query = 'items[*]'
    else:
        query = 'items[?metadata.namespace==\'%s\']' % (namespace)
    ctx.obj = OpenStruct(
        kubectl=kubectl,
        pods_cache=pods_cache,
        namespace_query=query,
        pod_re=re.compile(pod, re.IGNORECASE),
        container_re=re.compile(container, re.IGNORECASE),
    )

@cli.command()
@click.option('-c', '--columns', default=','.join(COLUMN_MAP.keys()), show_default=True,
              help='specify specific columns to show')
@click.pass_obj
def list(obj, columns):
    '''List available pods and containers for current context.'''

    columns = [c.strip() for c in columns.split(',')]
    print tabulate(each_match(obj, columns), headers=columns)

@cli.command(context_settings=dict(ignore_unknown_options=True))
@click.option('-s', '--shell', default='/bin/sh', show_default=True,
              help='alternate shell used for remote execution')
@click.option('-i', '--interactive', is_flag=True,
              help='require interactive session '
                   '(works with REPLs like shells or other command instances needing input)')
@click.option('-a', '--async', is_flag=True,
              help='run commands asynchronously (incompatible with "interactive")')
@click.option('-p', '--prefix', is_flag=True,
              help='add a prefix to all output indicating the pod and container names '
                   '(incompatible with "interactive")')
@click.argument('command')
@click.argument('arguments', nargs=-1, type=click.UNPROCESSED)
@click.pass_obj
def each(obj, shell, interactive, async, prefix, command, arguments):
    '''Execute a command remotely for each pod matched.'''

    kubectl = obj['kubectl']
    kexec_args = ['exec']
    if prefix:
        kexec = kubectl.call_prefix
        if interactive:
            click.get_current_context().fail('Interactive and prefix do not operate together')
    elif async:
        kexec = kubectl.call_async
        if interactive:
            click.get_current_context().fail('Interactive and async do not operate together')
    else:
        kexec = kubectl.call
        if interactive:
            kexec_args += ['-ti']

    remote_args = ['exec', command] + [pipes.quote(a) for a in arguments]
    remote_cmd = [shell, '-c', ' '.join(remote_args)]

    for (namespace, pod_name, containers) in each_match(obj):
        for container in containers:
            args = kexec_args[:] # copy
            if prefix: args.append('[%s:%s] ' % (pod_name, container))
            args += ['-n', namespace, '-c', container, pod_name, '--'] + remote_cmd
            kexec(*args)

    if async:
        kubectl.wait()

    if kubectl.final_rc != 0:
        click.get_current_context().exit(kubectl.final_rc)

@cli.command()
@click.option('-f', '--follow', is_flag=True,
              help='stream new logs until interrupted')
@click.argument('number', default=click.get_terminal_size()[1])
@click.pass_obj
def tail(obj, follow, number):
    '''Show recent logs from containers for each pod matched.'''

    kubectl = obj['kubectl']
    log_args = ['--tail', str(number)]
    if follow:
        log_args.append('-f')

    for (namespace, pod_name, containers) in each_match(obj):
        for container in containers:
            prefix = '[%s:%s] ' % (pod_name, container)
            args = ['-n', namespace, '-c', container] + log_args + [pod_name]
            kubectl.call_prefix('logs', prefix, *args)

    kubectl.wait()
    if kubectl.final_rc != 0:
        click.get_current_context().exit(kubectl.final_rc)

def each_match(obj, columns=['namespace', 'name', 'containers']):
    container_index = columns.index('containers') if 'containers' in columns else None
    cols = ['name', 'containers'] + columns
    # FIXME: use set and indices map: {v: i for i, v enumerate(cols)}
    for pod in each_pod(obj, cols):
        (pod_name, containers), col_values = pod[:2], pod[2:] # FIXME: this is duplicating cols!
        if not obj.pod_re.match(pod_name):
            continue
        matched_containers = [
            container for container in containers if obj.container_re.match(container)
        ]
        if len(matched_containers) < 1:
            continue
        if container_index: # overwrite with only matched items
            col_values[container_index] = matched_containers
        yield(col_values)

def each_pod(obj, columns):
    query = obj.namespace_query + '.[' + ','.join([COLUMN_MAP[c] for c in columns]) + ']'
    pods = obj.pods_cache.obj()
    for pod in jmespath.search(query, pods):
        yield pod

@cli.command(context_settings=dict(ignore_unknown_options=True))
@click.argument('command')
@click.argument('arguments', nargs=-1, type=click.UNPROCESSED)
@click.pass_obj
def call(obj, command, arguments):
    '''Generic proxy for any other kubectl request'''
    kubectl = obj['kubectl']
    items = kubectl.call_json(command, *arguments)['items']
    print tabulate(items, headers='keys')

if __name__ == '__main__':
    cli()
