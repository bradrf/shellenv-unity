#!/usr/bin/env python

import sys
import os
import logging
import re
import string
import subprocess
import json
import time
import pipes
import click
import jmespath

from configstruct import OpenStruct
from fnmatch import fnmatch
from threading import Thread
from tabulate import tabulate, tabulate_formats


# CONSIDER: getting to container node directory? fog logs, etc? /var/lib/docker/containers/

class Cache(object):
    def __init__(self, path, seconds, retriever, *retriever_args):
        self.path = path
        self.seconds = seconds
        self.retriever = retriever
        self.retriever_args = retriever_args
        self._obj = None
        self._expiry = None

    def obj(self):
        self._consider_update()
        return self._obj

    def _consider_update(self):
        if self._is_stale():
            self._update()
        elif not self._obj:
            with open(self.path) as f:
                self._obj = json.load(f)

    def _is_stale(self):
        if not self._expiry:
            if not os.path.exists(self.path):
                return True
            self._set_expiry()
        return self._expiry < time.time()

    def _update(self):
        self._obj = self.retriever(*self.retriever_args)
        with open(self.path, 'wb') as f:
            json.dump(self._obj, f)
        self._set_expiry()

    def _set_expiry(self):
        self._expiry = os.path.getmtime(self.path) + self.seconds

class BackgroundPopen(subprocess.Popen):
    @staticmethod
    def prefix_handler(prefix, io):
        return lambda line: io.write(prefix + line)

    @staticmethod
    def _proxy_lines(pipe, handler):
        with pipe:
            for line in pipe:
                handler(line)

    def __init__(self, out_handler, err_handler, *args, **kwargs):
        kwargs['stdout'] = subprocess.PIPE
        kwargs['stderr'] = subprocess.PIPE
        super(self.__class__, self).__init__(*args, **kwargs)
        Thread(target=self._proxy_lines, args=[self.stdout, out_handler]).start()
        Thread(target=self._proxy_lines, args=[self.stderr, err_handler]).start()

class KubeCtl(object):
    def __init__(self):
        self._kubectl = subprocess.check_output('which kubectl', shell=True).strip()
        self._processes = []
        self._threads = []
        self.final_rc = 0

    @property
    def context(self):
        return subprocess.check_output(self._commandline('config', 'current-context')).strip()

    def call(self, cmd, *args):
        cl = self._commandline(cmd, *args)
        return self._check(cl, subprocess.call(cl))

    def call_capture(self, cmd, *args):
        cl = self._commandline(cmd, *args)
        return subprocess.check_output(cl)

    def call_json(self, cmd, *args):
        return json.loads(self.call_capture(cmd, '--output=json', *args))

    def call_async(self, cmd, *args):
        cl = self._commandline(cmd, *args)
        self._processes.append((cl, subprocess.Popen(cl)))
        return 0

    def call_prefix(self, cmd, prefix, *args):
        out_handler = BackgroundPopen.prefix_handler(prefix, sys.stdout)
        err_handler = BackgroundPopen.prefix_handler('[ERR] ' + prefix, sys.stderr)
        cl = self._commandline(cmd, *args)
        self._processes.append((cl, BackgroundPopen(out_handler, err_handler, cl)))
        return 0

    def wait(self):
        procs = self._processes
        self._process = []
        for cl, proc in procs:
            self._check(cl, proc.wait())
        return self.final_rc

    def _commandline(self, command, *args):
        commandline = (self._kubectl, command) + args
        _logger.debug(' '.join(commandline))
        return commandline

    def _check(self, cl, rc):
        if rc != 0:
            self._final_rc = rc
            _logger.warn('%s => exit status: %d' % (' '.join(cl), rc))
        return rc


class Container(object):
    def __init__(self, name, ready, state, highlight=False):
        self.name = name
        self.ready = ready
        self.state = state
        self._highlight = highlight

    def __repr__(self):
        if self.ready or not self._highlight:
            rstr = self.ready
        else:
            rstr = '\033[30m\033[43m%s\033[0m' % (self.ready)
        return 'name:%s ready:%s state:%s' % (self.name, rstr, json.dumps(self.state))


######################################################################

ANY_NAMESPACE = '.'

COLUMN_MAP = {
    'name': 'metadata.name',
    'namespace': 'metadata.namespace',
    'node': 'spec.nodeName',
    'node-ip': 'status.hostIP',
    'status': 'status.phase',
    'containers': 'status.containerStatuses[*].[name,ready,state]',
}

BN = os.path.basename(__file__)
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s #%(process)d] %(levelname)-8s %(name)-12s %(message)s',
    datefmt='%Y-%m-%dT%H:%M:%S%z'
)
_logger = logging.getLogger(BN)


def each_match(obj, columns=['namespace', 'name', 'containers']):
    highlight = sys.stdout.isatty()
    container_index = columns.index('containers') if 'containers' in columns else None
    cols = ['name', 'containers'] + columns
    # FIXME: use set and indices map: {v: i for i, v enumerate(cols)}
    for pod in each_pod(obj, cols):
        (pod_name, container_info), col_values = pod[:2], pod[2:] # FIXME: this is duplicating cols!
        if not obj.pod_re.match(pod_name):
            continue
        containers = []
        for (name, ready, state) in container_info:
            if not obj.container_re.match(name):
                continue
            containers.append(Container(name, ready, state, highlight))
        if len(containers) < 1:
            continue
        if container_index > -1:
            col_values[container_index] = containers
        yield(col_values)

def each_pod(obj, columns):
    query = obj.namespace_query + '.[' + ','.join([COLUMN_MAP[c] for c in columns]) + ']'
    pods = obj.pods_cache.obj()
    for pod in jmespath.search(query, pods):
        yield pod


# TODO: consider ability to use --context w/o needing to switch
#       (be best if this can be saved in a configstruct!)
@click.group(invoke_without_command=True, context_settings=dict(help_option_names=['-h', '--help']))
@click.option('--cache-seconds', default=300, show_default=True,
              help='change number of seconds to keep pod info cached')
@click.option('-l', '--log-level', default='info',
              type=click.Choice(['debug', 'info', 'warning', 'error', 'critical']),
              help='set logging level')
@click.option('-f', '--format', 'table_format',
              type=click.Choice(tabulate_formats), default='simple', show_default=True,
              help='output format of tabular data (e.g. listing)')
@click.option('--no-headers', is_flag=True, help='disable table headers')
@click.argument('namespace')
@click.argument('pod')
@click.argument('container')
@click.pass_context
def cli(ctx, cache_seconds, log_level, table_format, no_headers, namespace, pod, container):
    '''Simple wrapper to help find specific Kubernetes pods and containers and run asynchronous
    commands.

    NAMESPACE   provide a namespace restriction or a period to select all
    POD         provide a regular expression to select one or more pods
    CONTAINER   provide a regular expression to select one or more containers
    '''

    _logger.level = getattr(logging, log_level.upper())
    kubectl = KubeCtl()
    pods_cache_fn = os.path.join(os.path.expanduser('~'), '.%s_%s_pods' % (BN, kubectl.context))
    pods_cache = Cache(pods_cache_fn, cache_seconds,
                       kubectl.call_json, 'get', 'pods', '--all-namespaces')
    # TODO: support glob matching?
    if namespace == ANY_NAMESPACE:
        query = 'items[*]'
    else:
        query = 'items[?metadata.namespace==\'%s\']' % (namespace)
    ctx.obj = OpenStruct(
        table_format=table_format,
        no_headers=no_headers,
        kubectl=kubectl,
        pods_cache=pods_cache,
        namespace_query=query,
        pod_re=re.compile(pod, re.IGNORECASE),
        container_re=re.compile(container, re.IGNORECASE),
    )
    if not ctx.invoked_subcommand:
        ctx.invoke(list_pods)


@cli.command(name='list')
@click.option('-c', '--columns', default=','.join(COLUMN_MAP.keys()), show_default=True,
              help='specify specific columns to show')
@click.pass_obj
def list_pods(obj, columns):
    '''List available pods and containers for current context.'''
    columns = [c.strip() for c in columns.split(',')]
    headers = [] if obj.no_headers else columns
    container_index = columns.index('containers')
    if container_index > -1:
        rows = []
        for row in each_match(obj, columns):
            items = []
            containers = []
            for (i, item) in enumerate(row):
                if i == container_index:
                    containers = [str(c) for c in item]
                else:
                    items.append(item)
            blank = ['' for i in items]
            for i, container in enumerate(containers):
                if i == 0:
                    rows.append(items + [container])
                else:
                    rows.append(blank + [container])
    else:
        rows = each_match(obj, columns)
    print tabulate(rows, headers=headers, tablefmt=obj.table_format)


@cli.command()
@click.pass_obj
def webui(obj):
    '''List dashboard links for matching pods. Three or fewer will be opened automatically.'''
    ansi_escape = re.compile(r'\x1b[^m]*m')
    info = ansi_escape.sub('', obj.kubectl.call_capture('cluster-info'))
    dash_endpoint = re.search(r'kubernetes-dashboard.*?(http\S+)', info).group(1)
    urls = []
    for (namespace, pod_name, containers) in each_match(obj):
        pod_path = '/#/pod/%s/%s?namespace=%s' % (namespace, pod_name, namespace)
        urls.append(dash_endpoint + pod_path)
    if len(urls) < 4:
        for url in urls:
            print url
            click.launch(url)
    else:
        for url in urls:
            print url


# FIX TO allow "real" term in remote exec (pass along env?)

@cli.command()
@click.argument('repl')
@click.argument('arguments', nargs=-1, type=click.UNPROCESSED)
@click.pass_context
def repl(ctx, repl, arguments):
    '''Start an interactive Read-Eval-Print Loop (REPL), e.g. bash, rails console, etc.'''
    ctx.invoke(each, interactive=True, command=repl, arguments=arguments)


@cli.command(context_settings=dict(ignore_unknown_options=True))
@click.option('-s', '--shell', default='/bin/sh', show_default=True,
              help='alternate shell used for remote execution')
@click.option('-i', '--interactive', is_flag=True,
              help='require interactive session '
                   '(works with REPLs like shells or other command instances needing input)')
@click.option('-a', '--async', is_flag=True,
              help='run commands asynchronously (incompatible with "interactive")')
@click.option('-p', '--prefix', is_flag=True,
              help='add a prefix to all output indicating the pod and container names '
                   '(incompatible with "interactive")')
@click.argument('command')
@click.argument('arguments', nargs=-1, type=click.UNPROCESSED)
@click.pass_obj
def each(obj, shell, interactive, async, prefix, command, arguments):
    '''Execute a command remotely for each pod matched.'''

    kubectl = obj['kubectl']
    kexec_args = ['exec']
    if prefix:
        kexec = kubectl.call_prefix
        if interactive:
            click.get_current_context().fail('Interactive and prefix do not operate together')
    elif async:
        kexec = kubectl.call_async
        if interactive:
            click.get_current_context().fail('Interactive and async do not operate together')
    else:
        kexec = kubectl.call
        if interactive:
            kexec_args += ['-ti']

    remote_args = ['exec', command] + [pipes.quote(a) for a in arguments]
    remote_cmd = [shell, '-c', ' '.join(remote_args)]

    for (namespace, pod_name, containers) in each_match(obj):
        for container in containers:
            if not container.ready:
                _logger.warn('skipping ' + str(container))
                continue
            args = kexec_args[:] # copy
            if prefix: args.append('[%s:%s] ' % (pod_name, container.name))
            args += ['-n', namespace, '-c', container.name, pod_name, '--'] + remote_cmd
            kexec(*args)

    if async:
        kubectl.wait()

    if kubectl.final_rc != 0:
        click.get_current_context().exit(kubectl.final_rc)


@cli.command()
@click.option('-f', '--follow', is_flag=True,
              help='stream new logs until interrupted')
@click.option('-p', '--prefix', is_flag=True,
              help='add a prefix to all output indicating the pod and container names')
@click.argument('number', default=10)
@click.pass_obj
def tail(obj, follow, prefix, number):
    '''Show recent logs from containers for each pod matched.'''

    kubectl = obj['kubectl']
    log_args = ['--tail', str(number)]

    if follow:
        log_args.append('-f')

    for (namespace, pod_name, containers) in each_match(obj):
        for container in containers:
            if not container.ready:
                _logger.warn('skipping ' + str(container))
                continue
            args = ['-n', namespace, '-c', container.name] + log_args + [pod_name]
            if prefix:
                prefix = '[%s:%s] ' % (pod_name, container.name)
                kubectl.call_prefix('logs', prefix, *args)
            else:
                kubectl.call_async('logs', *args)

    kubectl.wait()
    if kubectl.final_rc != 0:
        click.get_current_context().exit(kubectl.final_rc)

@cli.command(context_settings=dict(ignore_unknown_options=True))
@click.argument('command')
@click.argument('arguments', nargs=-1, type=click.UNPROCESSED)
@click.pass_obj
def call(obj, command, arguments):
    '''Generic proxy for any other kubectl request'''
    kubectl = obj['kubectl']
    items = kubectl.call_json(command, *arguments)['items']
    headers = [] if obj.no_headers else 'keys'
    print tabulate(items, headers=headers, tablefmt=obj.table_format)


if __name__ == '__main__':
    cli()
